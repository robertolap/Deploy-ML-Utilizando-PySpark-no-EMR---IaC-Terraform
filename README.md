# Implementação e Deploy de Machine Learning com PySpark no Amazon EMR

O Projeto  tem como objetivo principal a implementação e o deploy de um stack avançado de treinamento distribuído de Machine Learning utilizando PySpark no Amazon Elastic MapReduce (EMR). A ideia é aproveitar o processamento distribuído para treinar modelos de Machine Learning em larga escala, otimizando o uso de recursos e reduzindo o tempo necessário para o treinamento.O foco é facilidade de subir uma infra AWS com código terraform, o ML foi apenas um caso de uso que pode ser aplicado.

## Objetivos

- Utilizar PySpark, uma interface Python para o Apache Spark, para lidar com desafios comuns de Big Data, permitindo análises complexas e processamento de grandes volumes de dados de forma eficiente.
- Configurar um cluster EMR na AWS para executar tarefas de Machine Learning distribuídas.
- Projetar um stack de treinamento escalável e resiliente, aproveitando os serviços da AWS para gerenciamento de recursos e monitoramento.
- Facilitar o deploy automatizado e a integração contínua por meio de scripts e templates de infraestrutura como código, garantindo replicabilidade e consistência do ambiente.

## Componentes Principais

- Configuração de um cluster EMR na AWS.
- Utilização de PySpark para treinamento distribuído de modelos de Machine Learning.
- Implementação de boas práticas em Ciência de Dados, incluindo preparação de dados, seleção de modelos e avaliação de desempenho em um contexto distribuído.

## Fonte de Dados

Os dados usados no projeto foram preparados com base nos dados disponíveis no seguinte link: [Stanford AI Group - Sentiment Analysis](https://ai.stanford.edu/~amaas/data/sentiment)

Este projeto visa oferecer uma solução robusta para o treinamento de modelos de Machine Learning capazes de lidar com os desafios de dados em escala de petabytes, sendo ideal para organizações que buscam insights profundos a partir de grandes conjuntos de dados.
